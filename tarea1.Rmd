---
title: "`Tarea_1:` Analisís de la expresión Génica usando Deep Learning"
subtitle: "Herramientas y Algoritmos en Bioinformática"
author: "Diego de Pablo, estudiante de Bioinformática, Universidad de Málaga"
profesor: "Montes Torres Julio"
date: "`r format(Sys.time(), '%A %d, %B %Y')`"
output: 
  html_document:
    theme: spacelab
    number_sections: true
    toc: true
    toc_float: true
    code_folding: "hide"
    fontsize: 12pt
editor_options: 
  markdown: 
    wrap: sentence
---

```{=html}
<style>
/* Estilos generales */
h1, h2, h3 {
    color: #2E8B57; /* Color de los títulos - verde bosque */
    font-family: 'Arial', sans-serif; /* Fuente de los títulos */
    font-weight: bold; /* Negrita para los títulos */
}
  /* Tamaños específicos de los títulos */
  h1 {
      font-size: 20px; /* Tamaño más pequeño para h1 */
  }
  h2 {
      font-size: 18px; /* Tamaño más pequeño para h2 */
  }
  h3 {
      font-size: 16px; /* Tamaño más pequeño para h3 */
  }
  
/* Párrafos y texto normal */
p {
    color: #000000; /* Asegura que el texto de los párrafos sea negro */
    line-height: 1.6; /* Aumenta el espacio entre líneas para mejor legibilidad */
}

/* Estilos personalizados para detalles */
.custom-details {
    border: 2px solid #32CD32; /* Borde verde */
    border-radius: 8px;
    background-color: #f0fff0; /* Fondo verde claro */
    padding: 15px;
    margin: 15px 0;
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); /* Sombra suave */
}

.custom-details summary {
    font-weight: bold;
    color: #32CD32; /* Color del texto verde */
    cursor: pointer;
}

/* Estilos para el recuadro verde */
.green-alert {
    border: 1px solid #32CD32; /* Borde verde */
    background-color: #f0fff0; /* Fondo verde claro */
    color: #006400; /* Color del texto verde oscuro */
    padding: 15px;
    border-radius: 5px;
    margin-bottom: 20px;
    font-size: 15px;
}

</style>
```
*Este proyecto tiene como objetivo comprender diversas herramienas que permiten entrenar una red de aprendizaje profundo a través del marco H2O, con el fin de predecir el estado de pacientes de cáncer de riñón (fallecidos vs. vivos). Se utiliza un conjunto de datos con 267 casos de pacientes fallecidos y 753 controles vivos, con más de 20,000 genes por paciente. Además se usa la función glmnet para evaluar un modelo de regresión LASSO con las mismas características que se seleccionaron para la red de aprendizaje profundo y se contrastaron los resultados.*

# Preparación del trabajo

Este trabajo se podría dividir en 3 etapas, la primera referente a la preparación del código principal declarando aquellas funciones necesarias como las métricas de evaluacion para comenzar el desarrollo de una red de aprendizaje profundo, luego vendría el código principal que es el propio entrenamiento de la red de aprendizaje y por último contrastar los resultados obtenidos con un modelo de regresión LASSO.

```{r inicialización, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Limpiar el entorno de trabajo
rm(list = ls())  # Elimina todos los objetos en el entorno global
gc()  # Liberar memoria no utilizada

# Función para verificar si una librería está instalada, si no lo está, la instala
instalar_paquete <- function(paquete) {
  if (!requireNamespace(paquete, quietly = TRUE)) {
    install.packages(paquete, dependencies = TRUE)
  }
  library(paquete, character.only = TRUE)
}

# Lista de librerías necesarias para esta entrega
librerias <- c("pROC", "h2o", "uuid", "caret")

# Aplicamos la función a cada librería
invisible(lapply(librerias, instalar_paquete))

# Configuración de knitr
knitr::opts_chunk$set(echo = TRUE)

```

```{r instalar_version_reciente_H2O, eval = FALSE}
# The following two commands remove any previously installed H2O packages for R.
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }

# Next, we download packages that H2O depends on.
pkgs <- c("RCurl","jsonlite")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}

# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos="https://h2o-release.s3.amazonaws.com/h2o/rel-3.46.0/6/R")

# Finally, let's load H2O and start up an H2O cluster
library(h2o)
h2o.init()
```


```{r medir_tiempo}
# Registra el tiempo antes de compilar el archivo RMarkdown
start_time <- Sys.time()


```


## Evaluación de Modelos de Clasificación

A pesar de que es el inicio del trabajo se debe empezar definiendo las métricas que se usarán para evaluar el rendimiento de cada modelo entrenado, se evalúa utilizando métricas de clasificación como precisión y AUC para los conjuntos de entrenamiento y prueba.
Estas métricas se calculan a través de la función `get.classification.measures()`.

```{r model-evaluation-measures}
get.classification.measures <- function(true.class, pred.probs) {
     
     true.class <- as.numeric(true.class) # convert FALSE/TRUE to 0/1
     pred.class <- as.numeric(pred.probs > 0.5)
     
     cases.idx         <- which(true.class == 1)
     controls.idx      <- which(true.class == 0)
     
     res <- data.frame("accuracy"=0)
     
     # Accuracy
     res$accuracy <- sum(true.class == pred.class) / length(true.class)
     
     # Area under the Receiver-Operator Curve and Confidence Intervals
     res$AUC <- as.numeric(pROC::auc(response = true.class, predictor = pred.probs))
     
     return(unlist(res))
}
```

Los valores de AUC y precisión se calculan para cada conjunto de entrenamiento y prueba, y se almacenan en una matriz llamada `perfs.mat`.
Esta matriz se utiliza para almacenar los resultados de cada repetición de la validación cruzada.
Donde aquellos resultados más cercanos a 1 indicarán mejores resultados.

## Entrenamiento y Optimización de Redes Neuronales Profundas con H2O: Búsqueda de Parámetros Óptimos

En este bloque de código, se presenta una función `deepnet.training` diseñada para entrenar una red neuronal profunda utilizando la librería H2O.
La función comienza separando los datos en un conjunto de entrenamiento y validación, luego define un rango de parámetros que serán probados para encontrar la configuración óptima del modelo.
La búsqueda de parámetros se realiza de manera *aleatoria*, probando diferentes combinaciones de parámetros de activación, tasa de aprendizaje, dropout y otras configuraciones.
Finalmente, el modelo que obtenga el mejor desempeño en el conjunto de validación se selecciona para entrenar un modelo final utilizando todos los datos de entrenamiento disponibles.

```{r busqueda_param}
deepnet.training <- function(x, y, inner.folds) {
     y <- plyr::revalue(factor(y), c("0"="no", "1"="yes"))
     
     my.uuid <- gsub("-", "", UUIDgenerate())
     
     #split train in 80% train and 20% validation
     train.ids = sort(sample(1:nrow(x), size = floor(nrow(x)*0.8)))
     val.ids   = setdiff(1:nrow(x), train.ids)
     
     X.train = x[train.ids,]
     X.val   = x[val.ids,]
     Y.train = y[train.ids]
     Y.val   = y[val.ids]
     
     data.train <- cbind(outcome=Y.train, as.data.frame(X.train))
     data.train <- h2o::as.h2o(data.train, paste0("data.train.",my.uuid))
     data.val   <- cbind(outcome=Y.val, as.data.frame(X.val))
     data.val   <- h2o::as.h2o(data.val, paste0("data.val.",my.uuid))
     
     #deepnet parameters to try
     rand_activation     <- RAND.ACTIVATION
     rand_rho            <- seq(0.9, 0.99, 1e-3)
     rand_epsilon        <- c(1e-10,1e-9,1e-8,1e-7,1e-6,1e-5,1e-4)
     rand_input_dropout  <- seq(RAND.MIN.INPUT.DROPOUT, RAND.MAX.INPUT.DROPOUT, 1e-4)
     rand_l1             <- seq(RAND.MIN.L1, RAND.MAX.L1, 1e-4)
     rand_l2             <- seq(RAND.MIN.L2, RAND.MAX.L2, 1e-4)
     
     RAND.MAX.NEURONS.PER.LAYER = min(RAND.MAX.NEURONS.PER.LAYER, ncol(x))
     MAX.RUNTIME.SECS = MAX.RUNTIME.SECS/(RAND.MAX.NUM.HIDDEN.LAYERS-RAND.MIN.NUM.HIDDEN.LAYERS+1)
     bestgrids = list()
     for (netsize in RAND.MIN.NUM.HIDDEN.LAYERS:RAND.MAX.NUM.HIDDEN.LAYERS) {
          rand_hidden         <- lapply(lapply(1:500,
                                               function(x) RAND.MIN.NEURONS.PER.LAYER+sample(RAND.MAX.NEURONS.PER.LAYER-RAND.MIN.NEURONS.PER.LAYER, netsize, replace=F)),
                                        function(x) sort(x, decreasing = T))
          rand_hidden_dropout <- lapply(lapply(1:500,
                                               function (x) sample(seq(RAND.MIN.HIDDEN.DROPOUT, RAND.MAX.HIDDEN.DROPOUT, 1e-4), netsize, replace = F)),
                                        function(x) sort(x, decreasing = T))
          
          hyper_params <- list(activation = rand_activation, rho = rand_rho, epsilon = rand_epsilon,
                               hidden = rand_hidden, input_dropout_ratio = rand_input_dropout, hidden_dropout_ratios = rand_hidden_dropout,
                               l1 = rand_l1, l2 = rand_l2)
          search_criteria = list(strategy = "RandomDiscrete",
                                 max_models = NUM.RANDOM.TRIALS, max_runtime_secs = MAX.RUNTIME.SECS,
                                 seed=123456)
          
          model_grid <- h2o.grid("deeplearning",
                                 grid_id = paste0("gridsize.",netsize,".",my.uuid),
                                 hyper_params = hyper_params,
                                 search_criteria = search_criteria,
                                 x = colnames(x),
                                 y = "outcome",
                                 training_frame = data.train,
                                 validation_frame = data.val,
                                 balance_classes = T,
                                 epochs = TRIAL.EPOCHS,
                                 stopping_rounds = 3,
                                 stopping_tolerance = 0.02,
                                 stopping_metric = "AUC")
          
          aucs.train.perf = c()
          aucs.val.perf   = c()
          for (mi in model_grid@model_ids) {
               aucs.train.perf = c(aucs.train.perf, h2o.auc(h2o.getModel(mi)))
               aucs.val.perf   = c(aucs.val.perf, h2o.auc(h2o.getModel(mi), valid = T))
          }
          
          #
          bestgrids[[paste0("size",netsize)]] = h2o.getModel(model_grid@model_ids[[which.max(aucs.val.perf)]])
     }
     
     #grab best deepnet and use its parameter to fit a final deepnet to the complete train set
     best.uuid <- gsub("-", "", UUIDgenerate())
     best.model.tried = bestgrids[[which.max(sapply(bestgrids, function(x) h2o.auc(x, valid = T)))]]
     
     data <- cbind(outcome=y, as.data.frame(x))
     data <- h2o::as.h2o(data, paste0("data.",best.uuid))
     
     model <- h2o.deeplearning(x=colnames(x), y="outcome",
                               training_frame = data, model_id = paste0("bestmodel.",best.uuid),
                               activation = best.model.tried@parameters$activation,
                               hidden = best.model.tried@parameters$hidden,
                               epochs = EPOCHS,
                               rho = best.model.tried@parameters$rho,
                               epsilon = best.model.tried@parameters$epsilon,
                               input_dropout_ratio = best.model.tried@parameters$input_dropout_ratio,
                               hidden_dropout_ratios = best.model.tried@parameters$hidden_dropout_ratios,
                               l1 = best.model.tried@parameters$l1,
                               l2 = best.model.tried@parameters$l2,
                               stopping_rounds = 3,
                               stopping_tolerance = 0.02,
                               stopping_metric = "AUC",
                               balance_classes = T,
                               export_weights_and_biases = T
     )
     
     return(list(id=model@model_id, deepnet=model,
                 parameters=unlist(model@allparameters[c("activation","rho","epsilon","hidden","epochs","input_dropout_ratio","hidden_dropout_ratios","l1","l2")])))
}
```

## Predicción con Red Neuronal Profunda Utilizando H2O

Este bloque de código define la función deepnet.predictions, que se encarga de realizar predicciones utilizando un modelo de red neuronal profunda previamente entrenado con H2O.
La función convierte los datos de entrada en un formato compatible con H2O, realiza la predicción, y extrae los resultados en forma de probabilidades.
Se asegura de que no se generen probabilidades negativas, lo cual indicaría un problema con la configuración del modelo.

```{r prediccion_red}
deepnet.predictions <- function(model, x) {
     my.uuid     <- gsub("-", "", UUIDgenerate())
     newdata.hex <- h2o::as.h2o(as.data.frame(x), paste0("newdata.",my.uuid))
     predictions <- as.numeric(as.matrix(predict(model$deepnet, newdata = newdata.hex)[,"yes"]))
     h2o::h2o.rm(paste0("newdata.",my.uuid))
     gc()
     
     if (any(predictions<0)) stop("Negative probabilities predicted... Check the configuration of the trained deepnet")
          
     return(predictions)
}
```

## Prueba `t de Student` para Comparación de Medias

La función `univar.ttest` realiza una prueba t de Student para comparar las medias de dos grupos: controles (cuando *y == 0)* y casos (cuando *y == 1*).
La función devuelve el valor p asociado a la prueba, que indica si las medias de los dos grupos son estadísticamente diferentes.

```{r t_student}
univar.ttest <- function(x, y) {
     controls = x[y==0]
     cases = x[y==1]
     
     return(t.test(controls, cases)$p.value)
}
```

## Reducción de Características Usando Prueba t y Correlación

La `función ttest`.feature.reduction selecciona características relevantes usando la prueba t para comparar dos grupos y luego reduce la dimensionalidad eliminando características altamente correlacionadas hasta un número máximo definido.

```{r}
ttest.feature.reduction <- function(myX, myY, pval.thres = 0.05, max.vars = 200) {
     pvals = apply(myX, 2, function(x, y) univar.ttest(x,y), myY)
     
     myX = myX[, pvals < pval.thres]
     
     cutoff = 0.95
     while (ncol(myX)>max.vars) {
          cormatrix = stats::cor(as.matrix(myX))
          hc = findCorrelation(abs(cormatrix), cutoff=cutoff) # putt any value as a "cutoff"
          if (length(hc)>0){
               hc = sort(hc)
               myX = myX[,-c(hc)]
          }
          cutoff = cutoff-0.05
     }
     
     return(colnames(myX))
}


```

# Entrenamiento de la Red Neuronal Profunda



Este código realiza un proceso de validación cruzada (10-fold CV) sobre un conjunto de datos para entrenar (extraídos desde Rdata) y evaluar una red neuronal profunda (DeepNet), utilizando un enfoque de selección de características y entrenando el modelo en un entorno distribuido utilizando **H2O**. 

Para fácilitar el entendimiento y observar de mejor manera en que partes del código se tardan más además de poder separar las partes que interesa modificar para mejorar el rendimiento, se ha dividido en secciones que se explican a continuación:

## Parámetros de Filtrado de Datos

Estas variables controlan la selección de las características que se utilizarán en el modelo, lo que puede mejorar la eficiencia y precisión del entrenamiento.

```{r filtrado}
DATABASE = "KIPAN"
REP.INIT = 1 #starting repetition id for several repetitions of 10-fold-CV
REP.END  = 1 #ending repetition id for several repetitions of 10-fold-CV

DATASET.FILE     = "KIPAN__illuminahiseq_rnaseqv2__Level_3__RSEM_genes_normalized.data.RData"
SAVE.RDATA.FILE  = paste0("ttestcor-deepnet_rep_", REP.INIT, "_", REP.END, ".RData")
SAVE.CSV.FILE    = paste0("ttestcor-deepnet_rep_", REP.INIT, "_", REP.END, ".csv")

#Filtering parameters
PVAL.THRES = 0.001
MAX.VARS = 270
```

- **`PVAL.THRES`**: Umbral de p-valor para la selección de características. Reducir el umbral (por ejemplo, de `0.001` a `0.0001`) podría seleccionar menos características, pero más relevantes. A su vez, esto reduce el tiempo de entrenamiento.
- **`MAX.VARS`**: Número máximo de características a retener después de la selección de características. Ajustar este valor (por ejemplo, cambiar de `270` a `100`) puede ayudar a reducir la dimensionalidad del modelo, mejorando la velocidad de entrenamiento y evitando el sobreajuste.

## Parámetros de la Red Neuronal

Son fundamentales para la definición y optimización de la red neuronal, afectando tanto los resultados como la eficiencia computacional.

```{r param}
#DeepNets parameters
NUM.RANDOM.TRIALS = 500
MAX.RUNTIME.SECS = 600  # per fold, maximum spend 10 minutes trying different deepnets to select the best one => 100 minutes to run 10-fold-CV
TRIAL.EPOCHS = 100
EPOCHS = 100 #originalmente 2000
RAND.ACTIVATION = c("RectifierWithDropout","TanhWithDropout","MaxoutWithDropout")
RAND.MIN.NUM.HIDDEN.LAYERS  = 2
RAND.MAX.NUM.HIDDEN.LAYERS  = 4
RAND.MIN.NEURONS.PER.LAYER  = 10
RAND.MAX.NEURONS.PER.LAYER  = 200
RAND.MIN.INPUT.DROPOUT      = 1e-3
RAND.MAX.INPUT.DROPOUT      = 0.1
RAND.MIN.HIDDEN.DROPOUT     = 1e-3
RAND.MAX.HIDDEN.DROPOUT     = 0.1
RAND.MIN.L1                 = 1e-3
RAND.MAX.L1                 = 0.1
RAND.MIN.L2                 = 1e-3
RAND.MAX.L2                 = 0.1
```

- **`NUM.RANDOM.TRIALS`**: Número de intentos aleatorios para ajustar los hiperparámetros de la red.¡Reducir el número de intentos (por ejemplo, de `500` a `100`) podría disminuir el tiempo de entrenamiento, aunque a diferencia de los otros puntos el reducir la cantidad de intentos puede hacer que no sé encuentre la mejor solución.

- **`MAX.RUNTIME.SECS`**: Tiempo máximo permitido para entrenar cada modelo. Disminuir este valor (por ejemplo, de `600` a `300` segundos) puede ayudar a reducir la carga computacional, aunque limita la convergencia de los modelos.

- **`RAND.MIN.NEURONS.PER.LAYER`** y **`RAND.MAX.NEURONS.PER.LAYER`**: Rango de neuronas por capa en la red. Ajustar el número de neuronas (por ejemplo, de `10-200` a `20-100`) puede equilibrar el desempeño del modelo con la carga computacional. Reducir el número de neuronas puede acelerar el entrenamiento pero disminuir la capacidad del modelo para aprender patrones complejos.

- **`RAND.MIN.L1`** y **`RAND.MAX.L1`**: Rango de regularización L1 para evitar sobreajuste. Incrementar la regularización L1 (por ejemplo, de `1e-3` a `1e-2`) puede ayudar a mejorar la generalización y reducir el riesgo de sobreajuste, aunque podría ralentizar ligeramente el entrenamiento.

## Parámetros de H2O

Estos parámetros controlan la configuración del servidor H2O, influyendo en el uso de recursos y la paralelización del proceso de entrenamiento.

```{r h2o_param}
# H2O parameters
nthreads                    = 6 # En mi caso tengo un Intel Core i7-1165G7 con 4 núcleos y 8 hilos, quiero mantener el portatil en buen estado y como no tengo prisa en los resultados, pongo 6 hilos para no causarle estrés mayor a la máquina, usando -1 en nhtreads se usan todos los hilos disponibles
max_mem_size                = "12g" # En mi caso tengo 16 GB de RAM, por lo que pongo 10 GB para no saturar la memoria

```

- **`nthreads`**: Número de hilos de CPU utilizados por H2O. en este caso se decide usar 6 en vez del máximo para evitar sobrecargar el sistema y permitir el uso de otros recursos mientras se entrena el modelo.

- **`max_mem_size`**: Tamaño máximo de memoria RAM asignada al servidor H2O.

## Carga y evaluación de los datos

Este código está cargando un conjunto de datos, configurando el entorno para entrenamiento de un modelo de Machine Learning y preparando los datos para su normalización y evaluación. 

```{r carga_datos}

#cargamos los datos
load(DATASET.FILE)

set.seed(69)

# Number of observations
N = nrow(datainfo$data)
# Number of predictors
P = (ncol(datainfo$data)-1)

print(paste("#samples:", N))
print(paste("#variables:", P))

X = datainfo$data[,-1]
y = datainfo$data[,1]

#normalize the data
#to avoid problems with memory, the normalization is make in two steps
X[,1:floor(P/2)] <- scale(X[,1:floor(P/2)])
X[,(floor(P/2)+1):P] <- scale(X[,(floor(P/2)+1):P])

simul <- NULL
perfs.mat <- matrix(NA, nrow=10*((REP.END-REP.INIT)+1), ncol=5)
colnames(perfs.mat) <- c("repetition","acc.train","auc.train","acc.test","auc.test")
right.row=1

```

Se puede apreciar como de los 267 casos (fallecidos) y 753 controles (vivos) se obtienen 1020 muestras que cada una tiene 20144 genes representado en variables, lo que hace que el conjunto de datos sea muy grande y complejo.


## Entrenamiento de Red Neuronal Profunda con Validación Cruzada y Selección de Características Univariantes

Se realiza un ciclo de validación cruzada (10-fold cross-validation) sobre varios repeticiones del experimento, donde se entrenan redes neuronales profundas utilizando la biblioteca h2o. En cada repetición, se aplica una selección de características univariantes (basada en pruebas t) para reducir las variables a las más relevantes, seguida de un proceso de ajuste de parámetros con validación interna. Luego, se entrena un modelo de red neuronal profunda utilizando las características retenidas y se evalúa su desempeño en los conjuntos de entrenamiento y prueba. Los resultados de rendimiento, junto con las características seleccionadas y los parámetros del modelo, se guardan para su posterior análisis.


```{r}
# loop over several repetitions of cross-validation
for (rep in seq(REP.INIT, REP.END)) {
     cat(paste0("Repetition ", rep, "\n\n"))
     
     #the following line obtains the folds for 10-fold CV;
     folds <- datainfo$folds[datainfo$folds[,1]==rep, 2:ncol(datainfo$folds)]
     
     num.outter.folds <- ncol(folds)
     iter.res = NULL
     start.time = Sys.time()
     #loop over different folds
     for (ff in 1:num.outter.folds) {
          cat(paste0("CV ", ff, "-fold\n"))
          
          #obtain the training and test ids and their respective subsets
          train.ids   <- which(folds[, ff] != -1)
          test.ids    <- which(folds[, ff] == -1)
          X.train     <- X[train.ids,]
          X.test      <- X[test.ids,]
          Y.train     <- y[train.ids]
          Y.test      <- y[test.ids]
          
          # inner folds to be used in glmnet to learn lambda
          inner.folds <- folds[train.ids, ff]
          
          
          ########################################################################################
          # ANY FS PROCEDURE, CHI-SQUARED OR ANY OTHER HERE, in this a univariate feature selection with
          # multiple testing correction followed by a procedure that gets rid of highly correlated genes
          # in case more than 200 genes were retained
          retained.features = ttest.feature.reduction(X.train, Y.train, pval.thres = PVAL.THRES, max.vars = MAX.VARS)
          print(paste0(length(retained.features), " genes retained..."))
          X.train = X.train[,retained.features,drop=FALSE]
          X.test  = X.test[,retained.features,drop=FALSE]
          
          ########################################################################################
          # AND NOW FIT A MODEL (LASSO, DEEPNETS, OR ANY OTHER) WITH THE RETAINED FEATURES
          # In this case, train a deep net
          #start (or connect) to h2o server
          h2o.init(nthreads = -1, max_mem_size = "2G", ip = "127.0.0.1")

          Sys.sleep(2)

          model <- deepnet.training(x=X.train, y=Y.train, inner.folds=inner.folds)
          print(model$parameters)

          ########################################################################################

          #number of optimal predictors selected by lasso
          iter.res[[paste0("cvfold",ff)]][["retained.predictors"]] <- retained.features
          iter.res[[paste0("cvfold",ff)]][["deepnet.parameters"]]  <- model$parameters

          #compute train predictions over the train set, removing the outcome since we don't know it
          train.predictions <- deepnet.predictions(model = model, x = X.train)
          #compute test predictions over the test set, removing the outcome since we don't know it
          test.predictions <- deepnet.predictions(model = model, x = X.test)


          #compute classification measures within this test-fold
          train.auc <- get.classification.measures(true.class = Y.train, pred.probs = train.predictions)
          test.auc  <- get.classification.measures(true.class = Y.test, pred.probs = test.predictions)

          iter.res[[paste0("cvfold",ff)]][["train.perf"]] <- train.auc
          iter.res[[paste0("cvfold",ff)]][["test.perf"]]  <- test.auc

          perfs.mat[right.row,] <- c(rep, train.auc, test.auc)
          print(perfs.mat[right.row,])
          right.row = right.row+1

          h2o.shutdown(FALSE)
          Sys.sleep(2)

          write.csv(perfs.mat, file=SAVE.CSV.FILE, quote=F, row.names=F)
     } #end ff
     
     time.in.mins = as.numeric(difftime(Sys.time(), start.time, units="mins"))
     simul[[paste0("repetition",rep)]] = list(folds=iter.res, time.in.mins=time.in.mins)
     
     save(simul, file=SAVE.RDATA.FILE, compress="xz")
} #end rep

```

Comentar como para este caso es comparable en cuanto resultados, pero lasso puede ser superior en cuanto a gasto computacional y resultados en algunos casoss


```{r tiempo_final}
# Registra el tiempo después de la compilación
end_time <- Sys.time()

# Calcula y muestra el tiempo de ejecución
execution_time <- end_time - start_time
print(paste("Tiempo de compilación:", execution_time))
```



**Prueba a modificar algunos de los parámetros tras haber ejecutado el código original y responde a las preguntas:**

-   ¿Qué cambios has hecho? ¿Por qué?
-   ¿Te ha surgido algún problema durante la ejecución del código?¿Cuál?¿Cómo lo has resuelto?
-   ¿Has obtenido resultados significativamente distintos (acc, auc)?

**Opcional: con el paquete glmnet, incluye en el bucle el entrenamiento de una modelo de regressión con LASSO y evalúalo (debes haberlo hecho en Minería de datos):**

-   Compara los resultados obtenidos con LASSO con los que produce la red de aprendizaje profundo. ¿Es LASSO competitivo?¿Merece la pena el mayor tiempo de entrenamiento dedicado a la red?